Hebbian learning
`w_{ij} = (1/n) ∑_{μ=1}^{n} ϵ_{i}^{μ} ϵ_{j}^{μ}`
Storkey learning
\[ \Delta w_{ij} = \eta (\epsilon_{i} \epsilon_{j} - \epsilon_{i} w_{ij} \sum_{k \neq i,j} w_{ik} \epsilon_{k} - w_{ij} \sum_{k \neq i,j} w_{jk} \epsilon_{k}) \]
